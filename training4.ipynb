{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a53e4678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting split-folders\n",
      "  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: opencv-python-headless in /home/derrickle/anaconda3/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: scikit-learn in /home/derrickle/anaconda3/lib/python3.12/site-packages (1.5.1)\n",
      "Requirement already satisfied: scikit-image in /home/derrickle/anaconda3/lib/python3.12/site-packages (0.24.0)\n",
      "Requirement already satisfied: joblib in /home/derrickle/anaconda3/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: tqdm in /home/derrickle/anaconda3/lib/python3.12/site-packages (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/derrickle/anaconda3/lib/python3.12/site-packages (from opencv-python-headless) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/derrickle/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/derrickle/anaconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/derrickle/anaconda3/lib/python3.12/site-packages (from scikit-image) (3.3)\n",
      "Requirement already satisfied: pillow>=9.1 in /home/derrickle/anaconda3/lib/python3.12/site-packages (from scikit-image) (10.4.0)\n",
      "Requirement already satisfied: imageio>=2.33 in /home/derrickle/anaconda3/lib/python3.12/site-packages (from scikit-image) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/derrickle/anaconda3/lib/python3.12/site-packages (from scikit-image) (2023.4.12)\n",
      "Requirement already satisfied: packaging>=21 in /home/derrickle/anaconda3/lib/python3.12/site-packages (from scikit-image) (24.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /home/derrickle/anaconda3/lib/python3.12/site-packages (from scikit-image) (0.4)\n",
      "Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
      "Installing collected packages: split-folders\n",
      "Successfully installed split-folders-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Hybrid Model Training with Train/Validation Split\n",
    "# We'll split our data like a coach splits a team for practice and testing, extract features (like a detective with a checklist), and train a Random Forest model.\n",
    "\n",
    "# %%\n",
    "%pip install split-folders opencv-python-headless scikit-learn scikit-image joblib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264f7ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 41628 files [00:04, 9516.66 files/s] \n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Step 1: Split the Dataset into Train and Validation Sets\n",
    "\n",
    "# %%\n",
    "import splitfolders\n",
    "\n",
    "splitfolders.ratio(\n",
    "    \"Dataset/preprocessed_images\", \n",
    "    output=\"Dataset/split_preprocessed_images\", \n",
    "    seed=42, \n",
    "    ratio=(.8, .2)  # 80% train, 20% val\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 2: Feature Extraction Functions\n",
    "\n",
    "# %%\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern\n",
    "import os\n",
    "\n",
    "def extract_features(img):\n",
    "    \"\"\"Detective's checklist: color, texture, shape clues.\"\"\"\n",
    "    features = []\n",
    "    # Color: HSV histogram\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hist_h = cv2.calcHist([hsv], [0], None, [8], [0, 180]).flatten()\n",
    "    hist_s = cv2.calcHist([hsv], [1], None, [8], [0, 256]).flatten()\n",
    "    hist_v = cv2.calcHist([hsv], [2], None, [8], [0, 256]).flatten()\n",
    "    features.extend(hist_h)\n",
    "    features.extend(hist_s)\n",
    "    features.extend(hist_v)\n",
    "    # Texture: LBP\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    lbp = local_binary_pattern(gray, P=8, R=1, method='uniform')\n",
    "    (hist_lbp, _) = np.histogram(lbp.ravel(), bins=np.arange(0, 11), range=(0, 10))\n",
    "    features.extend(hist_lbp)\n",
    "    # Shape: Largest contour area\n",
    "    contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    largest_area = max([cv2.contourArea(cnt) for cnt in contours], default=0)\n",
    "    features.append(largest_area)\n",
    "    return np.array(features, dtype=np.float32)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 3: Prepare Data Loaders for Train/Val\n",
    "\n",
    "# %%\n",
    "import glob\n",
    "\n",
    "def load_data(image_folder):\n",
    "    \"\"\"Like sorting players into their positions (X = features, y = labels).\"\"\"\n",
    "    X, y = [], []\n",
    "    class_names = sorted(os.listdir(image_folder))\n",
    "    class_to_idx = {name: idx for idx, name in enumerate(class_names)}\n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(image_folder, class_name)\n",
    "        for img_file in glob.glob(os.path.join(class_dir, \"*.jpg\")):\n",
    "            img = cv2.imread(img_file)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            img[:, :, 1] = img[:, :, 1] * 0.6  # Green channel emphasis\n",
    "            feats = extract_features(img)\n",
    "            X.append(feats)\n",
    "            y.append(class_to_idx[class_name])\n",
    "    return np.array(X), np.array(y), class_to_idx\n",
    "\n",
    "# Load training data\n",
    "X_train, y_train, class_to_idx = load_data(\"Dataset/split_preprocessed_images/train\")\n",
    "# Load validation data\n",
    "X_val, y_val, _ = load_data(\"Dataset/split_preprocessed_images/val\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 4: Train Random Forest Model\n",
    "\n",
    "# %%\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Calculate class weights (like giving more attention to underrepresented players)\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=150,\n",
    "    class_weight=class_weight_dict,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 5: Evaluate Model\n",
    "\n",
    "# %%\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = rf.predict(X_val)\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "print(classification_report(y_val, y_pred, target_names=[idx_to_class[i] for i in sorted(idx_to_class)]))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 6: Save Model\n",
    "\n",
    "# %%\n",
    "import joblib\n",
    "joblib.dump(rf, \"hybrid_rf_model_training4.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
