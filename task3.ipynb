{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b87ec1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Now import other libraries or define your model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee0fd23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: zlibwapi.dll is accessible!\n"
     ]
    }
   ],
   "source": [
    "import ctypes\n",
    "try:\n",
    "    ctypes.WinDLL('zlibwapi.dll')  # Test loading the DLL\n",
    "    print(\"Success: zlibwapi.dll is accessible!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b106cd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA RTX A4000, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "from tensorflow.keras.mixed_precision import LossScaleOptimizer\n",
    "from keras.layers import Dropout, BatchNormalization\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "set_global_policy('mixed_float16')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f312c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# Clear previous sessions\n",
    "K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2591867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bf482c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load metadata\n",
    "metadata_path = \"Dataset/meta_train.csv\"\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "metadata_df.set_index('image_id', inplace=True)\n",
    "\n",
    "# Path to preprocessed folder\n",
    "base_path = \"Dataset/preprocessed_images\"\n",
    "diseases = os.listdir(base_path)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for disease in diseases:\n",
    "    disease_path = os.path.join(base_path, disease)\n",
    "    files = os.listdir(disease_path)\n",
    "\n",
    "    base_names = sorted(set(f.split('_')[0] for f in files))\n",
    "\n",
    "    for base in base_names:\n",
    "        try:\n",
    "            # Construct paths\n",
    "            red_path = os.path.join(disease_path, f\"{base}_red.jpg\")\n",
    "            green_path = os.path.join(disease_path, f\"{base}_green.jpg\")\n",
    "            blue_path = os.path.join(disease_path, f\"{base}_blue.jpg\")\n",
    "\n",
    "\n",
    "            if not all(os.path.exists(p) for p in [red_path, green_path, blue_path]):\n",
    "                print(f\"Skipping {base}: not all image variants found.\")\n",
    "                continue\n",
    "\n",
    "            # Load and resize each channel as grayscale\n",
    "            red = np.array(Image.open(red_path).resize((299, 299)).convert('L'))\n",
    "            green = np.array(Image.open(green_path).resize((299, 299)).convert('L'))\n",
    "            blue = np.array(Image.open(blue_path).resize((299, 299)).convert('L'))\n",
    "\n",
    "\n",
    "            # Now stack them into (299, 299, 4)\n",
    "            stacked = np.stack([red, green, blue], axis=-1).astype(np.float32)\n",
    "            stacked /= 255.0  # Normalize\n",
    "\n",
    "            # Check metadata\n",
    "            meta_key = f\"{base}.jpg\"\n",
    "            if meta_key not in metadata_df.index:\n",
    "                print(f\"Metadata not found for {meta_key}\")\n",
    "                continue\n",
    "\n",
    "            age = float(metadata_df.loc[meta_key, 'age'])\n",
    "\n",
    "            X.append(stacked)\n",
    "            y.append(age)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {base}: {e}\")\n",
    "\n",
    "# Convert to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20f0d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e31cad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (10407, 299, 299, 3)\n",
      "y shape: (10407,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c231749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define input\n",
    "# input_tensor = Input(shape=(299, 299, 3))\n",
    "\n",
    "# # Load EfficientNetB0 without pretrained weights\n",
    "# base_model = EfficientNetB0(input_tensor=input_tensor, include_top=False, weights=None, pooling='avg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfab1191",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run TensorDataset: Dst tensor is not initialized. [Op:TensorDataset]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run TensorDataset: Dst tensor is not initialized. [Op:TensorDataset]"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define input layer\n",
    "input_tensor = Input(shape=(299, 299, 3))\n",
    "\n",
    "# InceptionV3 with no weights\n",
    "base_model = EfficientNetB0(include_top=False, weights=None, input_tensor=input_tensor)\n",
    "\n",
    "\n",
    "# Regression head\n",
    "# Modify your model architecture:\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(256, activation='relu', kernel_regularizer=l2(0.05))(x)\n",
    "x = Dropout(0.7)(x)  # Increased from 0.5\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "output = Dense(1, activation='linear')(x)\n",
    "optimizer = Adam(learning_rate=tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.001,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9))\n",
    "optimizer = LossScaleOptimizer(optimizer)  # Wraps the optimizer\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=30, batch_size=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06344865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 2s 32ms/step - loss: 83.1406 - mae: 7.6736\n",
      "Validation MAE: 7.6736159324646\n"
     ]
    }
   ],
   "source": [
    "loss, mae = model.evaluate(X_val, y_val)\n",
    "print(\"Validation MAE:\", mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
