{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b87ec1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Now import other libraries or define your model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee0fd23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [WinError 193] %1 is not a valid Win32 application\n"
     ]
    }
   ],
   "source": [
    "import ctypes\n",
    "try:\n",
    "    ctypes.WinDLL('zlibwapi.dll')  # Test loading the DLL\n",
    "    print(\"Success: zlibwapi.dll is accessible!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b106cd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA RTX A4000, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "from tensorflow.keras.mixed_precision import LossScaleOptimizer\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "set_global_policy('mixed_float16')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f312c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# Clear previous sessions\n",
    "K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2591867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf482c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load metadata\n",
    "metadata_path = \"Dataset/meta_train.csv\"\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "metadata_df.set_index('image_id', inplace=True)\n",
    "\n",
    "# Path to preprocessed folder\n",
    "base_path = \"Dataset/preprocessed_images\"\n",
    "diseases = os.listdir(base_path)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for disease in diseases:\n",
    "    disease_path = os.path.join(base_path, disease)\n",
    "    files = os.listdir(disease_path)\n",
    "\n",
    "    base_names = sorted(set(f.split('_')[0] for f in files))\n",
    "\n",
    "    for base in base_names:\n",
    "        try:\n",
    "            # Construct paths\n",
    "            red_path = os.path.join(disease_path, f\"{base}_red.jpg\")\n",
    "            green_path = os.path.join(disease_path, f\"{base}_green.jpg\")\n",
    "            blue_path = os.path.join(disease_path, f\"{base}_blue.jpg\")\n",
    "\n",
    "\n",
    "            if not all(os.path.exists(p) for p in [red_path, green_path, blue_path]):\n",
    "                print(f\"Skipping {base}: not all image variants found.\")\n",
    "                continue\n",
    "\n",
    "            # Load and resize each channel as grayscale\n",
    "            red = np.array(Image.open(red_path).resize((128, 128)).convert('L'))\n",
    "            green = np.array(Image.open(green_path).resize((128, 128)).convert('L'))\n",
    "            blue = np.array(Image.open(blue_path).resize((128, 128)).convert('L'))\n",
    "\n",
    "\n",
    "            # Now stack them into (299, 299, 4)\n",
    "            stacked = np.stack([red, green, blue], axis=-1).astype(np.float32)\n",
    "            stacked /= 255.0  # Normalize\n",
    "\n",
    "            # Check metadata\n",
    "            meta_key = f\"{base}.jpg\"\n",
    "            if meta_key not in metadata_df.index:\n",
    "                print(f\"Metadata not found for {meta_key}\")\n",
    "                continue\n",
    "\n",
    "            age = float(metadata_df.loc[meta_key, 'age'])\n",
    "\n",
    "            X.append(stacked)\n",
    "            y.append(age)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {base}: {e}\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20f0d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e31cad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (10407, 224, 224, 3)\n",
      "y shape: (10407,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c231749b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# base_model = InceptionV3(\n",
    "#     input_shape=(299, 299, 3),\n",
    "#     include_top=False,\n",
    "#     weights=None,\n",
    "#     pooling='avg'\n",
    "# )\n",
    "# Define input\n",
    "# input_tensor = Input(shape=(299, 299, 3))\n",
    "\n",
    "# # Load EfficientNetB0 without pretrained weights\n",
    "# base_model = EfficientNetB0(input_tensor=input_tensor, include_top=False, weights=None, pooling='avg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfab1191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define input layer\n",
    "input_tensor = Input(shape=(128, 128, 3))\n",
    "\n",
    "# InceptionV3 with no weights\n",
    "base_model = EfficientNetB0(include_top=False, weights=None, input_tensor=input_tensor)\n",
    "\n",
    "# Regression head\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(1, activation='linear', dtype='float32')(x)\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "optimizer = LossScaleOptimizer(optimizer)  # Wraps the optimizer\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e0ce3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06344865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, mae = model.evaluate(X_val, y_val)\n",
    "# print(\"Validation MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f679d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mae = base_model.evaluate(X_val, y_val)\n",
    "print(\"Validation MAE:\", mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
