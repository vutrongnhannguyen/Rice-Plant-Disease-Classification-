{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd093f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Rice Disease Classification Prototype (Task 1)\n",
    "# **Hardware Requirements:** NVIDIA GPU (4GB+ VRAM) or CPU (may be slower)\n",
    "\n",
    "# %% [code]\n",
    "# Environment Setup\n",
    "%pip install tensorflow opencv-python-headless scikit-learn imbalanced-learn\n",
    "\n",
    "# %% [code]\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import cv2, os, json\n",
    "\n",
    "# Verify GPU availability\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Data Preparation Pipeline\n",
    "\n",
    "# %% [code]\n",
    "# Configuration\n",
    "DATA_PATH = '/path/to/train_images'\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "CLASS_NAMES = sorted(os.listdir(DATA_PATH))  # Get class names from directories\n",
    "\n",
    "# %% [code]\n",
    "# Custom data loader with real-time augmentation\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # 80-20 split\n",
    ")\n",
    "\n",
    "# Train generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    DATA_PATH,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "# Validation generator\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    DATA_PATH,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Lightweight Model Architecture\n",
    "\n",
    "# %% [code]\n",
    "def build_dwscnn(input_shape=(224,224,3), num_classes=10):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Initial feature extraction\n",
    "    x = layers.Conv2D(32, (3,3), activation='relu')(inputs)\n",
    "    x = layers.DepthwiseConv2D((3,3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(2,2)(x)\n",
    "    \n",
    "    # Depthwise block\n",
    "    x = layers.DepthwiseConv2D((3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(64, (1,1), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(2,2)(x)\n",
    "    \n",
    "    # Final layers\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "model = build_dwscnn()\n",
    "model.summary()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Class Balancing Strategy\n",
    "\n",
    "# %% [code]\n",
    "# Compute class weights\n",
    "class_counts = {cls: len(os.listdir(os.path.join(DATA_PATH, cls))) for cls in CLASS_NAMES}\n",
    "total = sum(class_counts.values())\n",
    "class_weights = {i: total/(len(class_counts)*count) for i, (cls, count) in enumerate(class_counts.items())}\n",
    "\n",
    "# %% [code]\n",
    "# Custom focal loss implementation\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        return -tf.reduce_sum(alpha * tf.pow(1. - pt, gamma) * tf.math.log(pt), axis=-1)\n",
    "    return focal_loss_fixed\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Training Configuration\n",
    "\n",
    "# %% [code]\n",
    "# Compile model with mixed precision\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=focal_loss(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3),\n",
    "    tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Prototype Training\n",
    "\n",
    "# %% [code]\n",
    "# Train with subset for prototyping\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,  # Reduced for quick iteration\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=50,\n",
    "    epochs=30,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Local Evaluation\n",
    "\n",
    "# %% [code]\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Accuracy Progress')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss Progress')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# %% [code]\n",
    "# Confusion matrix on validation set\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "val_preds = model.predict(val_generator)\n",
    "val_labels = val_generator.classes\n",
    "pred_classes = np.argmax(val_preds, axis=1)\n",
    "\n",
    "print(classification_report(val_labels, pred_classes, target_names=CLASS_NAMES))\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(confusion_matrix(val_labels, pred_classes), \n",
    "            annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
