{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d2a5194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 02:36:16.946009: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-15 02:36:16.946968: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-15 02:36:17.001098: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-15 02:36:17.016893: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747251377.064963  443872 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747251377.073383  443872 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747251377.147757  443872 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747251377.147803  443872 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747251377.147804  443872 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747251377.147806  443872 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-15 02:36:17.153716: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import optuna\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Dense, Dropout, \n",
    "                                   BatchNormalization, Input, GlobalAveragePooling2D, \n",
    "                                   Concatenate, Multiply)\n",
    "\n",
    "# === Initial Configuration ===\n",
    "config = {\n",
    "    \"epochs\": 1,\n",
    "    \"is_config_batch_size_param\": True,\n",
    "    \"batch_size\": 200,\n",
    "    \"initial_lr\": 0.001,\n",
    "    \"gpu_memory_limit\": 45,\n",
    "    \"target_size\": (480, 640), \n",
    "    \"input_shape\": (640, 480, 3),\n",
    "    \"data_path\": \"Dataset/merged_SMOT_train\",\n",
    "    \"csv_path\": \"processed_data/cleaned_metadata_short.csv\",\n",
    "    \"train_set_csv\": \"Model/training8_alex_incept_rgb_att_SMOT_aug_bay/training8_alex_incept_rgb_att_SMOT_aug_bay_train_set.csv\",\n",
    "    \"val_set_csv\": \"Model/training8_alex_incept_rgb_att_SMOT_aug_bay/training8_alex_incept_rgb_att_SMOT_aug_bay_validation_set.csv\",\n",
    "    \"history_csv\": \"Model/training8_alex_incept_rgb_att_SMOT_aug_bay/training8_alex_incept_rgb_att_SMOT_aug_bay_history.csv\",\n",
    "    \"best_model\": \"Model/training8_alex_incept_rgb_att_SMOT_aug_bay/training8_alex_incept_rgb_att_SMOT_aug_bay_best_model.keras\",\n",
    "    \"label_encoder_path\": \"Model/training8_alex_incept_rgb_att_SMOT_aug_bay/training8_alex_incept_rgb_att_SMOT_aug_bay_label_encoder.npy\",\n",
    "    \"color_channel\": \"\",\n",
    "    \"save_dir\": \"Model/training8_alex_incept_rgb_att_SMOT_aug_bay\",\n",
    "    \"n_trials\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4b4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*** Model Save is disanbled for testing purposes ***\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices=false'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d9d202",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 02:36:21.493159: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# === GPU Setup ===\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        policy = mixed_precision.Policy('float32')\n",
    "        mixed_precision.set_global_policy(policy)\n",
    "        \n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        tf.config.optimizer.set_jit(True)\n",
    "        tf.config.threading.set_intra_op_parallelism_threads(8)\n",
    "        tf.config.threading.set_inter_op_parallelism_threads(4)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "def cleanup_gpu_memory():\n",
    "    \"\"\"Force clear GPU memory\"\"\"\n",
    "    K.clear_session()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "        try:\n",
    "            for gpu in tf.config.list_physical_devices('GPU'):\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78a8a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Data Pipeline ===\n",
    "def load_and_preprocess_data(random_state=42, save_splits=True):\n",
    "    \"\"\"Load and split data with fixed random state for reproducibility\"\"\"\n",
    "    df = pd.read_csv(config[\"csv_path\"])\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    df['label_encoded'] = le.fit_transform(df['label'])\n",
    "    print(f\"Label classes: {le.classes_}\")\n",
    "    \n",
    "    with open(config['label_encoder_path'], 'wb') as f:\n",
    "        np.save(f, le.classes_)\n",
    "    \n",
    "    train_df, val_df = train_test_split(\n",
    "        df, \n",
    "        test_size=0.2, \n",
    "        stratify=df['label'],\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    \n",
    "    if save_splits:\n",
    "        train_df.to_csv(config['train_set_csv'], index=False)\n",
    "        val_df.to_csv(config['val_set_csv'], index=False)\n",
    "    \n",
    "    return train_df, val_df, le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92577bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    \"\"\" Generator for loading and augmenting rice images \"\"\"\n",
    "    def __init__(self, df, base_path, batch_size=32, target_size=(480, 640), shuffle=False, debug=False, config=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.base_path = base_path\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size  \n",
    "        self.shuffle = shuffle\n",
    "        self.debug = debug\n",
    "        self.indices = np.arange(len(df))\n",
    "        self.config = config if config else {}\n",
    "        \n",
    "        self.aug = A.Compose(config[\"augmentation\"])\n",
    "        \n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "        if self.debug:\n",
    "            self.visualize_samples()    \n",
    "            \n",
    "    def visualize_samples(self):        \n",
    "        try:\n",
    "            row = self.df.iloc[0]\n",
    "            img = self._load_image(row['image_id'], row['label'])\n",
    "            augmented = self.aug(image=img)\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            \n",
    "            # original\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"Original\\nShape: {img.shape}\")\n",
    "            \n",
    "            # augmented\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(augmented['image'])\n",
    "            plt.title(f\"Augmented\\nShape: {augmented['image'].shape}\")\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Visualization failed for {row['image_id']}: {str(e)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def _load_image(self, image_id, label):\n",
    "        img_path = os.path.join(\n",
    "            self.base_path,\n",
    "            label,\n",
    "            f\"{os.path.splitext(image_id)[0]}.jpg\"\n",
    "        )\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Image not found at {img_path}\")\n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        batch_df = self.df.iloc[batch_indices]\n",
    "        \n",
    "        X = np.zeros((len(batch_df), self.target_size[1], self.target_size[0], 3), dtype=np.float32) #(batch, height, width, channels)\n",
    "        y = np.zeros((len(batch_df),), dtype=np.int32)\n",
    "        \n",
    "        for i, (_, row) in enumerate(batch_df.iterrows()):\n",
    "            try:\n",
    "                img = self._load_image(row['image_id'], row['label'])\n",
    "                augmented = self.aug(image=img)\n",
    "                X[i] = augmented['image'] / 255.0\n",
    "                y[i] = row['label_encoded']\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {row['image_id']}: {str(e)}\")\n",
    "                X[i] = np.zeros((self.target_size[1], self.target_size[0], 3), dtype=np.float32) #(batch, height, width, channels)\n",
    "                y[i] = -1\n",
    "                \n",
    "        valid = y != -1\n",
    "        return X[valid], y[valid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dacc4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Model Architecture ===\n",
    "def se_block(input_tensor, ratio=16):\n",
    "    channels = input_tensor.shape[-1]\n",
    "    se = GlobalAveragePooling2D()(input_tensor)\n",
    "    se = Dense(channels // ratio, activation=\"relu\")(se)\n",
    "    se = Dense(channels, activation=\"sigmoid\")(se)\n",
    "    return Multiply()([input_tensor, se])\n",
    "\n",
    "def create_custom_alex_incept(input_shape, num_classes, conv_filters=96):    \n",
    "    inputs = Input(shape=input_shape, dtype=tf.float32) \n",
    "     \n",
    "    # Initial feature extraction\n",
    "    x = Conv2D(conv_filters, (7,7), strides=2, activation='relu', padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((3,3), strides=2)(x)\n",
    "    \n",
    "    x = se_block(x)\n",
    "\n",
    "    # Intermediate layers\n",
    "    x = Conv2D(256, (5,5), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((3,3), strides=2)(x)\n",
    "    \n",
    "    # Parallel paths\n",
    "    branch1 = Conv2D(128, (1,1), activation='relu', padding='same')(x)\n",
    "    branch1 = Conv2D(256, (3,3), activation='relu', padding='same')(branch1)\n",
    "    \n",
    "    branch2 = Conv2D(128, (1,1), activation='relu', padding='same')(x)\n",
    "    branch2 = Conv2D(256, (5,5), activation='relu', padding='same')(branch2)\n",
    "    \n",
    "    branch3 = Conv2D(128, (1,1), activation='relu', padding='same')(x)\n",
    "    branch3 = Conv2D(256, (3,3), dilation_rate=2, activation='relu', padding='same')(branch3)\n",
    "    \n",
    "    branch4 = MaxPooling2D((3,3), strides=1, padding='same')(x)\n",
    "    branch4 = Conv2D(256, (1,1), activation='relu', padding='same')(branch4)\n",
    "    \n",
    "    x = Concatenate()([branch1, branch2, branch3, branch4])\n",
    "        \n",
    "    # Final classification head\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu', name='features')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax', dtype=tf.float32)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbfeea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Optimization ===\n",
    "def train_for_optimization(config, trial):\n",
    "    cleanup_gpu_memory()\n",
    "    train_df, val_df, le = load_and_preprocess_data()\n",
    "    \n",
    "    model = create_custom_alex_incept(\n",
    "        config[\"input_shape\"], \n",
    "        len(le.classes_),\n",
    "        conv_filters=config.get(\"conv_filters\", 96)\n",
    "    )\n",
    "    \n",
    "    train_gen = DataGenerator(\n",
    "        train_df, config[\"data_path\"], \n",
    "        batch_size=config[\"batch_size\"],\n",
    "        target_size=config[\"target_size\"],\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    val_gen = DataGenerator(\n",
    "        val_df, config[\"data_path\"],\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        target_size=config[\"target_size\"],\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=AdamW(learning_rate=config[\"initial_lr\"]),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=config[\"n_trials\"],  \n",
    "        callbacks=[\n",
    "            TFKerasPruningCallback(trial, \"val_accuracy\"),\n",
    "            tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "        ],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    return max(history.history['val_accuracy'])\n",
    "\n",
    "# === Optimized Objective Function ===\n",
    "def objective(trial, config):\n",
    "    params = {\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True),\n",
    "        \"dropout_rate\": trial.suggest_float(\"dropout_rate\", 0.2, 0.8),\n",
    "        \"conv_filters\": trial.suggest_int(\"conv_filters\", 32, 256, step=32),\n",
    "    }\n",
    "    \n",
    "    current_config = config.copy()\n",
    "    current_config.update(params)\n",
    "    \n",
    "    print(f\"Current config: {current_config}\")\n",
    "    \n",
    "    return train_for_optimization(current_config, trial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2fe70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparameters(config, n_trials=30):\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5)\n",
    "    )\n",
    "    \n",
    "    study.optimize(lambda trial: objective(trial, config), n_trials=n_trials)\n",
    "    \n",
    "    # Visualization\n",
    "    # fig = plot_optimization_history(study)\n",
    "    # fig.show()\n",
    "    # fig = plot_param_importances(study)\n",
    "    # fig.show()\n",
    "    \n",
    "    return study.best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8629ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Final Training Function ===\n",
    "def train_final_model(config):\n",
    "    cleanup_gpu_memory()\n",
    "    train_df, val_df, le = load_and_preprocess_data()\n",
    "    \n",
    "    model = create_custom_alex_incept(\n",
    "        config[\"input_shape\"],\n",
    "        len(le.classes_),\n",
    "        conv_filters=config.get(\"conv_filters\", 96)\n",
    "    )\n",
    "    \n",
    "    train_gen = DataGenerator(\n",
    "        train_df, config[\"data_path\"],\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        target_size=config[\"target_size\"],\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    val_gen = DataGenerator(\n",
    "        val_df, config[\"data_path\"],\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        target_size=config[\"target_size\"],\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=AdamW(learning_rate=config[\"initial_lr\"]),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=config[\"epochs\"],\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                config[\"best_model\"],\n",
    "                save_best_only=True,\n",
    "                monitor='val_accuracy'\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56c5e173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(history):\n",
    "    \"\"\"Plot accuracy and loss\"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706a591d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_443872/3363036070.py:11: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(num_holes_range=[5, 10], hole_height_range=[0.01, 0.02], hole_width_range=[0.01, 0.02], max_holes=3, max_height=1, max_width=1),\n",
      "[I 2025-05-15 02:36:21,675] A new study created in memory with name: no-name-6b934465-686d-4773-8776-f7b261ff8b31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter optimization...\n",
      "Current config: {'epochs': 1, 'is_config_batch_size_param': True, 'batch_size': 32, 'initial_lr': 0.001, 'gpu_memory_limit': 45, 'target_size': (255, 255), 'input_shape': (255, 255, 3), 'data_path': 'Dataset/merged_SMOT_train', 'csv_path': 'processed_data/cleaned_metadata_short.csv', 'train_set_csv': 'Model/training8_alex_incept_rgb_att_SMOT_aug_bay/training8_alex_incept_rgb_att_SMOT_aug_bay_train_set.csv', 'val_set_csv': 'Model/training8_alex_incept_rgb_att_SMOT_aug_bay/training8_alex_incept_rgb_att_SMOT_aug_bay_validation_set.csv', 'history_csv': 'Model/training8_alex_incept_rgb_att_SMOT_aug_bay/training8_alex_incept_rgb_att_SMOT_aug_bay_history.csv', 'best_model': 'Model/training8_alex_incept_rgb_att_SMOT_aug_bay/training8_alex_incept_rgb_att_SMOT_aug_bay_best_model.keras', 'label_encoder_path': 'Model/training8_alex_incept_rgb_att_SMOT_aug_bay/training8_alex_incept_rgb_att_SMOT_aug_bay_label_encoder.npy', 'color_channel': '', 'save_dir': 'Model/training8_alex_incept_rgb_att_SMOT_aug_bay', 'n_trials': 3, 'augmentation': [Resize(p=1.0, height=255, interpolation=1, mask_interpolation=0, width=255), HueSaturationValue(p=0.5, hue_shift_limit=(-20.0, 20.0), sat_shift_limit=(-30.0, 30.0), val_shift_limit=(-20.0, 20.0)), CLAHE(p=0.5, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8)), CoarseDropout(p=0.5, fill=0.0, fill_mask=None, hole_height_range=(0.01, 0.02), hole_width_range=(0.01, 0.02), num_holes_range=(5, 10))], 'lr': 5.819784203689472e-05, 'dropout_rate': 0.3659307250243695, 'conv_filters': 256}\n",
      "Label classes: ['bacterial_leaf_blight' 'bacterial_panicle_blight' 'blast' 'brown_spot'\n",
      " 'dead_heart' 'downy_mildew']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-15 02:36:35,786] Trial 0 finished with value: 0.375 and parameters: {'lr': 5.819784203689472e-05, 'batch_size': 32, 'dropout_rate': 0.3659307250243695, 'conv_filters': 256}. Best is trial 0 with value: 0.375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current config: {'epochs': 1, 'is_config_batch_size_param': True, 'batch_size': 32, 'initial_lr': 0.001, 'gpu_memory_limit': 45, 'target_size': (255, 255), 'input_shape': (255, 255, 3), 'data_path': 'Dataset/merged_SMOT_train', 'csv_path': 'processed_data/cleaned_metadata_short.csv', 'train_set_csv': 'Model/training8_alex_incept_rgb_att_SMOT_aug_bay/training8_alex_incept_rgb_att_SMOT_aug_bay_train_set.csv', 'val_set_csv': 'Model/training8_alex_incept_rgb_att_SMOT_aug_bay/training8_alex_incept_rgb_att_SMOT_aug_bay_validation_set.csv', 'history_csv': 'Model/training8_alex_incept_rgb_att_SMOT_aug_bay/training8_alex_incept_rgb_att_SMOT_aug_bay_history.csv', 'best_model': 'Model/training8_alex_incept_rgb_att_SMOT_aug_bay/training8_alex_incept_rgb_att_SMOT_aug_bay_best_model.keras', 'label_encoder_path': 'Model/training8_alex_incept_rgb_att_SMOT_aug_bay/training8_alex_incept_rgb_att_SMOT_aug_bay_label_encoder.npy', 'color_channel': '', 'save_dir': 'Model/training8_alex_incept_rgb_att_SMOT_aug_bay', 'n_trials': 3, 'augmentation': [Resize(p=1.0, height=255, interpolation=1, mask_interpolation=0, width=255), HueSaturationValue(p=0.5, hue_shift_limit=(-20.0, 20.0), sat_shift_limit=(-30.0, 30.0), val_shift_limit=(-20.0, 20.0)), CLAHE(p=0.5, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8)), CoarseDropout(p=0.5, fill=0.0, fill_mask=None, hole_height_range=(0.01, 0.02), hole_width_range=(0.01, 0.02), num_holes_range=(5, 10))], 'lr': 0.000940980576803123, 'dropout_rate': 0.6796519503690852, 'conv_filters': 32}\n",
      "Label classes: ['bacterial_leaf_blight' 'bacterial_panicle_blight' 'blast' 'brown_spot'\n",
      " 'dead_heart' 'downy_mildew']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-15 02:36:41,833] Trial 1 finished with value: 0.25 and parameters: {'lr': 0.000940980576803123, 'batch_size': 32, 'dropout_rate': 0.6796519503690852, 'conv_filters': 32}. Best is trial 0 with value: 0.375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current config: {'epochs': 1, 'is_config_batch_size_param': True, 'batch_size': 16, 'initial_lr': 0.001, 'gpu_memory_limit': 45, 'target_size': (255, 255), 'input_shape': (255, 255, 3), 'data_path': 'Dataset/merged_SMOT_train', 'csv_path': 'processed_data/cleaned_metadata_short.csv', 'train_set_csv': 'Model/training8_alex_incept_rgb_att_SMOT_aug_bay/training8_alex_incept_rgb_att_SMOT_aug_bay_train_set.csv', 'val_set_csv': 'Model/training8_alex_incept_rgb_att_SMOT_aug_bay/training8_alex_incept_rgb_att_SMOT_aug_bay_validation_set.csv', 'history_csv': 'Model/training8_alex_incept_rgb_att_SMOT_aug_bay/training8_alex_incept_rgb_att_SMOT_aug_bay_history.csv', 'best_model': 'Model/training8_alex_incept_rgb_att_SMOT_aug_bay/training8_alex_incept_rgb_att_SMOT_aug_bay_best_model.keras', 'label_encoder_path': 'Model/training8_alex_incept_rgb_att_SMOT_aug_bay/training8_alex_incept_rgb_att_SMOT_aug_bay_label_encoder.npy', 'color_channel': '', 'save_dir': 'Model/training8_alex_incept_rgb_att_SMOT_aug_bay', 'n_trials': 3, 'augmentation': [Resize(p=1.0, height=255, interpolation=1, mask_interpolation=0, width=255), HueSaturationValue(p=0.5, hue_shift_limit=(-20.0, 20.0), sat_shift_limit=(-30.0, 30.0), val_shift_limit=(-20.0, 20.0)), CLAHE(p=0.5, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8)), CoarseDropout(p=0.5, fill=0.0, fill_mask=None, hole_height_range=(0.01, 0.02), hole_width_range=(0.01, 0.02), num_holes_range=(5, 10))], 'lr': 0.00014761714484951482, 'dropout_rate': 0.45552322653718125, 'conv_filters': 224}\n",
      "Label classes: ['bacterial_leaf_blight' 'bacterial_panicle_blight' 'blast' 'brown_spot'\n",
      " 'dead_heart' 'downy_mildew']\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x7f8a1cb667a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(config[\"save_dir\"], exist_ok=True)\n",
    "\n",
    "opt_config = {\n",
    "    **config,\n",
    "    \"target_size\": (255, 255),\n",
    "    \"input_shape\": (255, 255, 3),\n",
    "    \"augmentation\": [\n",
    "        A.Resize(width=255, height=255),\n",
    "        A.HueSaturationValue(p=0.5),\n",
    "        A.CLAHE(p=0.5),    \n",
    "        A.CoarseDropout(num_holes_range=[5, 10], hole_height_range=[0.01, 0.02], hole_width_range=[0.01, 0.02], max_holes=3, max_height=1, max_width=1),\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Run optimization\n",
    "print(\"Starting hyperparameter optimization...\")\n",
    "best_params = optimize_hyperparameters(opt_config, n_trials=config[\"n_trials\"])\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Run training\n",
    "final_config = {\n",
    "    **opt_config,\n",
    "    **best_params,\n",
    "}\n",
    "\n",
    "print(\"Starting final training...\")\n",
    "final_model, final_history = train_final_model(final_config)\n",
    "\n",
    "plot_accuracy_loss(final_history)\n",
    "\n",
    "# Save again for safety\n",
    "final_model.save(os.path.join(config[\"save_dir\"], 'final_model.keras'))\n",
    "with open(os.path.join(config[\"save_dir\"], 'training_history.pkl'), 'wb') as f:\n",
    "    pickle.dump(final_history.history, f)\n",
    "\n",
    "print(\"Training completed and model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804d6b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes, normalize=False, title=None):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fmt = '.2f'\n",
    "    else:\n",
    "        fmt = 'd'\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=fmt, xticklabels=classes, yticklabels=classes,\n",
    "                cmap='Blues', cbar=False)\n",
    "    \n",
    "    plt.title(title or 'Confusion Matrix')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_class_accuracy(y_true, y_pred, classes):\n",
    "    correct = (y_true == y_pred)\n",
    "    class_acc = []\n",
    "    for i in range(len(classes)):\n",
    "        idx = np.where(y_true == i)[0]\n",
    "        acc = np.mean(correct[idx]) if len(idx) > 0 else 0\n",
    "        class_acc.append(acc)\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(12,6))\n",
    "    \n",
    "    # Bar plot for class distribution\n",
    "    ax1.bar(classes, [np.sum(y_true == i) for i in range(len(classes))], \n",
    "            color='skyblue', alpha=0.7, label='Samples')\n",
    "    ax1.set_ylabel('Number of Samples', color='skyblue')\n",
    "    ax1.tick_params(axis='y', labelcolor='skyblue')\n",
    "    \n",
    "    # Line plot for accuracy\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(classes, class_acc, 'r-o', linewidth=2, markersize=8, \n",
    "             label='Accuracy')\n",
    "    ax2.set_ylabel('Accuracy', color='red')\n",
    "    ax2.tick_params(axis='y', labelcolor='red')\n",
    "    ax2.set_ylim(0, 1.1)\n",
    "    \n",
    "    plt.title('Class Distribution vs. Accuracy')\n",
    "    fig.legend(loc='upper right', bbox_to_anchor=(1,1), bbox_transform=ax1.transAxes)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confidence_distribution(model, eval_gen, classes):\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for i in range(len(eval_gen)):\n",
    "        x, y = eval_gen[i]\n",
    "        probs = model.predict(x, verbose=0)\n",
    "        all_probs.extend(probs.max(axis=1))\n",
    "        all_labels.extend(y)\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    for class_id in range(len(classes)):\n",
    "        class_probs = [p for p, l in zip(all_probs, all_labels) if l == class_id]\n",
    "        sns.kdeplot(class_probs, label=classes[class_id], fill=True)\n",
    "    \n",
    "    plt.xlabel('Prediction Confidence')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('Confidence Distribution per Class')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_error_types(y_true, y_pred, classes):\n",
    "    error_mask = (y_true != y_pred)\n",
    "    fp_counts = []\n",
    "    fn_counts = []\n",
    "    \n",
    "    for i in range(len(classes)):\n",
    "        fp = np.sum((y_pred == i) & (y_true != i))\n",
    "        fn = np.sum((y_true == i) & (y_pred != i))\n",
    "        fp_counts.append(fp)\n",
    "        fn_counts.append(fn)\n",
    "    \n",
    "    x = np.arange(len(classes))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12,6))\n",
    "    ax.bar(x - width/2, fp_counts, width, label='False Positives', color='salmon')\n",
    "    ax.bar(x + width/2, fn_counts, width, label='False Negatives', color='lightblue')\n",
    "    \n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('False Positives vs False Negatives per Class')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(classes, rotation=45)\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_topk_accuracy(y_true, y_probs, classes, k=3):\n",
    "    topk_correct = np.zeros(k)\n",
    "    \n",
    "    for i in range(1, k+1):\n",
    "        topk_pred = np.argsort(y_probs, axis=1)[:, -i:]\n",
    "        topk_correct[i-1] = np.mean([y_true[j] in topk_pred[j] for j in range(len(y_true))])\n",
    "    \n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.bar(range(1,k+1), topk_correct, color='teal')\n",
    "    plt.xticks(range(1,k+1))\n",
    "    plt.xlabel('Top-K')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Top-K Classification Accuracy (K=1 to {k})')\n",
    "    plt.ylim(0, 1.1)\n",
    "    \n",
    "    for i, acc in enumerate(topk_correct):\n",
    "        plt.text(i+1, acc+0.02, f\"{acc:.2%}\", ha='center')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def plot_feature_space(model, eval_gen, classes, n_samples=1000):\n",
    "    # Get feature extractor (remove last layer)\n",
    "    feature_model = tf.keras.Model(inputs=model.inputs, \n",
    "                                 outputs=model.layers[-2].output)\n",
    "    \n",
    "    # Get features and labels\n",
    "    features, labels = [], []\n",
    "    for i in range(min(10, len(eval_gen))):  # Limit batches for memory\n",
    "        x, y = eval_gen[i]\n",
    "        features.extend(feature_model.predict(x, verbose=0))\n",
    "        labels.extend(y)\n",
    "    \n",
    "    # Downsample if too many points\n",
    "    if len(features) > n_samples:\n",
    "        idx = np.random.choice(len(features), n_samples, replace=False)\n",
    "        features = np.array(features)[idx]\n",
    "        labels = np.array(labels)[idx]\n",
    "    else:\n",
    "        features = np.array(features)\n",
    "        labels = np.array(labels)\n",
    "    \n",
    "    # Reduce dimensionality\n",
    "    from sklearn.manifold import TSNE\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    features_2d = tsne.fit_transform(features)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12,8))\n",
    "    scatter = plt.scatter(features_2d[:,0], features_2d[:,1], \n",
    "                         c=labels, cmap='tab20', alpha=0.6)\n",
    "    \n",
    "    plt.title('t-SNE Visualization of Feature Space')\n",
    "    plt.legend(handles=scatter.legend_elements()[0], \n",
    "               labels=list(classes),\n",
    "               bbox_to_anchor=(1.05, 1), \n",
    "               loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_saved_model(use_val_set=True, config=None):\n",
    "    # Validate config\n",
    "    if not config:\n",
    "        raise ValueError(\"Configuration dictionary must be provided\")\n",
    "        \n",
    "    with open(config['label_encoder_path'], 'rb') as f:\n",
    "        le = LabelEncoder()\n",
    "        le.classes_ = np.load(f, allow_pickle=True)\n",
    "    \n",
    "    cleanup_gpu_memory()\n",
    "    model = tf.keras.models.load_model(config[\"best_model\"], compile=False)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=[\n",
    "            tf.keras.metrics.SparseCategoricalAccuracy(name='acc'),\n",
    "            tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3, name='top3_acc')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    eval_df = (pd.read_csv(config[\"val_set_csv\"]) \n",
    "                if use_val_set \n",
    "                else load_and_preprocess_data(save_splits=False)[1])\n",
    "    print(f\"\\nEvaluating on {len(eval_df)} samples (batch size: {config['batch_size']})\")\n",
    "    \n",
    "    eval_gen = DataGenerator(\n",
    "        df=eval_df,\n",
    "        base_path=config[\"data_path\"],\n",
    "        batch_size=config['batch_size'],\n",
    "        target_size=config[\"target_size\"],\n",
    "        shuffle=False,\n",
    "        debug=False,\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    # Inspect first batch\n",
    "    x_test, y_test = eval_gen[0]\n",
    "    print(\"\\n[DEBUG] First batch inspection:\")\n",
    "    print(f\"- Input shape: {x_test.shape}\")\n",
    "    print(f\"- Label shape: {y_test.shape}\")\n",
    "    print(f\"- Sample label: {y_test[0]} -> {le.classes_[y_test[0]]}\")\n",
    "\n",
    "    print(\"\\n=== Running Evaluation ===\")\n",
    "    results = model.evaluate(eval_gen, verbose=1, return_dict=True)\n",
    "    print(\"\\n[METRICS] Evaluation Results:\", results)\n",
    "    \n",
    "    y_true, y_pred = [], []\n",
    "    for i in range(len(eval_gen)):\n",
    "        x, y = eval_gen[i]\n",
    "        y_true.extend(y)\n",
    "        y_pred.extend(model.predict(x, verbose=0).argmax(axis=1))\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # Validation check\n",
    "    if len(y_true) != len(y_pred):\n",
    "        raise ValueError(f\"Label/prediction length mismatch! {len(y_true)} vs {len(y_pred)}\")\n",
    "    \n",
    "    # Print samples\n",
    "    print(\"\\n[PREDICTION SAMPLES] (True vs Predicted)\")\n",
    "    sample_indices = np.random.choice(len(y_true), size=min(5, len(y_true)), replace=False)\n",
    "    for idx in sample_indices:\n",
    "        print(f\"{le.classes_[y_true[idx]]} → {le.classes_[y_pred[idx]]} \"\n",
    "                f\"(Correct: {y_true[idx] == y_pred[idx]})\")\n",
    "    \n",
    "    print(\"\\n=== Detailed Metrics ===\")\n",
    "    \n",
    "    # Confusion Matrix Info\n",
    "    print(f\"\\nClasses: {list(le.classes_)}\")\n",
    "    print(f\"Total evaluated samples: {len(y_true)}\")\n",
    "    \n",
    "    # Plot confusion matrices\n",
    "    for normalize in [True, False]:\n",
    "        plot_confusion_matrix(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            classes=le.classes_,\n",
    "            normalize=normalize,\n",
    "            title=f\"Confusion Matrix ({'Normalized' if normalize else 'Counts'})\"\n",
    "        )\n",
    "        \n",
    "    plot_class_accuracy(y_true, y_pred, le.classes_)  \n",
    "    \n",
    "    plot_confidence_distribution(model, eval_gen, le.classes_)  \n",
    "    \n",
    "    plot_error_types(y_true, y_pred, le.classes_)\n",
    "    \n",
    "    # Classification report\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(\"\\n[CLASSIFICATION REPORT]\")\n",
    "    print(classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        target_names=le.classes_,\n",
    "        digits=4\n",
    "    ))\n",
    "    \n",
    "    return results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1203b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 50, 'is_config_batch_size_param': True, 'batch_size': 64, 'initial_lr': 0.001, 'gpu_memory_limit': 45, 'target_size': (255, 255), 'input_shape': (255, 255, 3), 'data_path': 'Dataset/merged_SMOT_train', 'csv_path': 'processed_data/cleaned_metadata_short.csv', 'train_set_csv': 'Model/training8_customCNN_rgb_att_SMOT_aug_bay_1/training8_customCNN_rgb_att_SMOT_aug_bay_1_train_set.csv', 'val_set_csv': 'Model/training8_customCNN_rgb_att_SMOT_aug_bay_1/training8_customCNN_rgb_att_SMOT_aug_bay_1_validation_set.csv', 'history_csv': 'Model/training8_customCNN_rgb_att_SMOT_aug_bay_1/training8_customCNN_rgb_att_SMOT_aug_bay_1_history.csv', 'best_model': 'Model/training8_customCNN_rgb_att_SMOT_aug_bay_1/training8_customCNN_rgb_att_SMOT_aug_bay_1_best_model.keras', 'label_encoder_path': 'Model/training8_customCNN_rgb_att_SMOT_aug_bay_1/training8_customCNN_rgb_att_SMOT_aug_bay_1_label_encoder.npy', 'color_channel': '', 'save_dir': 'Model/training8_customCNN_rgb_att_SMOT_aug_bay_1', 'n_trials': 2, 'lr': 0.0004297832897098259, 'dropout_rate': 0.38586038760896363, 'conv_filters': 128, 'augmentation': [Resize(p=1.0, height=255, interpolation=1, mask_interpolation=0, width=255), HueSaturationValue(p=0.5, hue_shift_limit=(-20.0, 20.0), sat_shift_limit=(-30.0, 30.0), val_shift_limit=(-20.0, 20.0)), CLAHE(p=0.5, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8)), CoarseDropout(p=0.5, fill=0.0, fill_mask=None, hole_height_range=(0.01, 0.02), hole_width_range=(0.01, 0.02), num_holes_range=(5, 10))]}\n",
      "Label classes: ['bacterial_leaf_blight' 'bacterial_panicle_blight' 'blast' 'brown_spot'\n",
      " 'dead_heart' 'downy_mildew']\n",
      "\n",
      "Evaluating on 8 samples\n",
      "{'epochs': 50, 'is_config_batch_size_param': True, 'batch_size': 64, 'initial_lr': 0.001, 'gpu_memory_limit': 45, 'target_size': (255, 255), 'input_shape': (255, 255, 3), 'data_path': 'Dataset/merged_SMOT_train', 'csv_path': 'processed_data/cleaned_metadata_short.csv', 'train_set_csv': 'Model/training8_customCNN_rgb_att_SMOT_aug_bay_1/training8_customCNN_rgb_att_SMOT_aug_bay_1_train_set.csv', 'val_set_csv': 'Model/training8_customCNN_rgb_att_SMOT_aug_bay_1/training8_customCNN_rgb_att_SMOT_aug_bay_1_validation_set.csv', 'history_csv': 'Model/training8_customCNN_rgb_att_SMOT_aug_bay_1/training8_customCNN_rgb_att_SMOT_aug_bay_1_history.csv', 'best_model': 'Model/training8_customCNN_rgb_att_SMOT_aug_bay_1/training8_customCNN_rgb_att_SMOT_aug_bay_1_best_model.keras', 'label_encoder_path': 'Model/training8_customCNN_rgb_att_SMOT_aug_bay_1/training8_customCNN_rgb_att_SMOT_aug_bay_1_label_encoder.npy', 'color_channel': '', 'save_dir': 'Model/training8_customCNN_rgb_att_SMOT_aug_bay_1', 'n_trials': 2, 'lr': 0.0004297832897098259, 'dropout_rate': 0.38586038760896363, 'conv_filters': 128, 'augmentation': [Resize(p=1.0, height=255, interpolation=1, mask_interpolation=0, width=255), HueSaturationValue(p=0.5, hue_shift_limit=(-20.0, 20.0), sat_shift_limit=(-30.0, 30.0), val_shift_limit=(-20.0, 20.0)), CLAHE(p=0.5, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8)), CoarseDropout(p=0.5, fill=0.0, fill_mask=None, hole_height_range=(0.01, 0.02), hole_width_range=(0.01, 0.02), num_holes_range=(5, 10))]}\n",
      "Evaluation failed: Graph execution error:\n",
      "\n",
      "Detected at node LogicalAnd_1 defined at (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "\n",
      "  File \"/tmp/ipykernel_347862/1247371265.py\", line 2, in <module>\n",
      "\n",
      "  File \"/tmp/ipykernel_347862/521710606.py\", line 46, in evaluate_saved_model\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 483, in evaluate\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 99, in test_step\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/trainers/trainer.py\", line 490, in compute_metrics\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 334, in update_state\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 21, in update_state\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/metrics/confusion_metrics.py\", line 378, in update_state\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/metrics/metrics_utils.py\", line 592, in update_confusion_matrix_variables\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/metrics/metrics_utils.py\", line 565, in weighted_assign_add\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/ops/numpy.py\", line 3686, in logical_and\n",
      "\n",
      "  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/numpy.py\", line 1629, in logical_and\n",
      "\n",
      "Incompatible shapes: [1,48] vs. [1,8]\n",
      "\t [[{{node LogicalAnd_1}}]] [Op:__inference_multi_step_on_iterator_19022]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node LogicalAnd_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_347862/1247371265.py\", line 2, in <module>\n\n  File \"/tmp/ipykernel_347862/521710606.py\", line 46, in evaluate_saved_model\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 483, in evaluate\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 99, in test_step\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/trainers/trainer.py\", line 490, in compute_metrics\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 334, in update_state\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 21, in update_state\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/metrics/confusion_metrics.py\", line 378, in update_state\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/metrics/metrics_utils.py\", line 592, in update_confusion_matrix_variables\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/metrics/metrics_utils.py\", line 565, in weighted_assign_add\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/ops/numpy.py\", line 3686, in logical_and\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/numpy.py\", line 1629, in logical_and\n\nIncompatible shapes: [1,48] vs. [1,8]\n\t [[{{node LogicalAnd_1}}]] [Op:__inference_multi_step_on_iterator_19022]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_config)\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m evaluate_saved_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel/training8_customCNN_rgb_att_SMOT_aug_bay_1/final_model.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m, use_val_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, input_config\u001b[38;5;241m=\u001b[39mfinal_config)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Access specific results:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[30], line 46\u001b[0m, in \u001b[0;36mevaluate_saved_model\u001b[0;34m(model_path, use_val_set, input_config)\u001b[0m\n\u001b[1;32m     36\u001b[0m eval_gen \u001b[38;5;241m=\u001b[39m RiceDataGenerator(\n\u001b[1;32m     37\u001b[0m     df\u001b[38;5;241m=\u001b[39meval_df,\n\u001b[1;32m     38\u001b[0m     base_path\u001b[38;5;241m=\u001b[39minput_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_path\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     config\u001b[38;5;241m=\u001b[39minput_config,\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# 1. Standard Evaluation Metrics\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(eval_gen, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[EVALUATION METRICS]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node LogicalAnd_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_347862/1247371265.py\", line 2, in <module>\n\n  File \"/tmp/ipykernel_347862/521710606.py\", line 46, in evaluate_saved_model\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 483, in evaluate\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 99, in test_step\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/trainers/trainer.py\", line 490, in compute_metrics\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 334, in update_state\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 21, in update_state\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/metrics/confusion_metrics.py\", line 378, in update_state\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/metrics/metrics_utils.py\", line 592, in update_confusion_matrix_variables\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/metrics/metrics_utils.py\", line 565, in weighted_assign_add\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/ops/numpy.py\", line 3686, in logical_and\n\n  File \"/home/derrickle/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/numpy.py\", line 1629, in logical_and\n\nIncompatible shapes: [1,48] vs. [1,8]\n\t [[{{node LogicalAnd_1}}]] [Op:__inference_multi_step_on_iterator_19022]"
     ]
    }
   ],
   "source": [
    "results = evaluate_saved_model(use_val_set=True, input_config=final_config)\n",
    "\n",
    "# Access specific results:\n",
    "print(\"Test Accuracy:\", results['metrics']['accuracy'])\n",
    "print(\"Class-wise Performance:\")\n",
    "print(pd.DataFrame(results['classification_report']).transpose())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
