{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ed62451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in /home/derrickle/anaconda3/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: scikit-learn in /home/derrickle/anaconda3/lib/python3.12/site-packages (1.5.1)\n",
      "Requirement already satisfied: scikit-image in /home/derrickle/anaconda3/lib/python3.12/site-packages (0.24.0)\n",
      "Requirement already satisfied: joblib in /home/derrickle/anaconda3/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: tqdm in /home/derrickle/anaconda3/lib/python3.12/site-packages (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/derrickle/anaconda3/lib/python3.12/site-packages (from opencv-python-headless) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/derrickle/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/derrickle/anaconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/derrickle/anaconda3/lib/python3.12/site-packages (from scikit-image) (3.3)\n",
      "Requirement already satisfied: pillow>=9.1 in /home/derrickle/anaconda3/lib/python3.12/site-packages (from scikit-image) (10.4.0)\n",
      "Requirement already satisfied: imageio>=2.33 in /home/derrickle/anaconda3/lib/python3.12/site-packages (from scikit-image) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/derrickle/anaconda3/lib/python3.12/site-packages (from scikit-image) (2023.4.12)\n",
      "Requirement already satisfied: packaging>=21 in /home/derrickle/anaconda3/lib/python3.12/site-packages (from scikit-image) (24.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /home/derrickle/anaconda3/lib/python3.12/site-packages (from scikit-image) (0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Hybrid Feature Engineered Model: Training Notebook\n",
    "# This notebook demonstrates how to extract hybrid features (color, texture, shape) from rice plant images and train a Random Forest classifier for disease classification, leveraging EDA insights.\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Install Required Packages\n",
    "\n",
    "# %%\n",
    "%pip install opencv-python-headless scikit-learn scikit-image joblib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061cc276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10407/10407 [01:27<00:00, 118.90it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (10407, 35)\n",
      "Labels shape: (10407,)\n",
      "Class weights: {0: 2.172651356993737, 1: 2.7386842105263156, 2: 3.0881305637982197, 3: 0.5987917146144994, 4: 1.0784455958549224, 5: 0.7217059639389737, 6: 1.6785483870967741, 7: 0.6528858218318695, 8: 0.5899659863945578, 9: 0.9565257352941177}\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "   bacterial_leaf_blight       0.92      0.83      0.87        96\n",
      "   bacterial_leaf_streak       0.90      0.92      0.91        76\n",
      "bacterial_panicle_blight       0.92      0.72      0.81        67\n",
      "                   blast       0.88      0.94      0.91       348\n",
      "              brown_spot       0.93      0.84      0.89       193\n",
      "              dead_heart       0.85      0.93      0.89       288\n",
      "            downy_mildew       0.94      0.85      0.89       124\n",
      "                   hispa       0.91      0.92      0.92       319\n",
      "                  normal       0.93      0.93      0.93       353\n",
      "                  tungro       0.91      0.89      0.90       218\n",
      "\n",
      "                accuracy                           0.90      2082\n",
      "               macro avg       0.91      0.88      0.89      2082\n",
      "            weighted avg       0.90      0.90      0.90      2082\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 80   1   0   4   2   2   0   4   1   2]\n",
      " [  1  70   0   1   0   1   0   0   2   1]\n",
      " [  1   0  48   3   0  13   0   0   2   0]\n",
      " [  0   2   0 328   3   3   1   4   5   2]\n",
      " [  0   1   1   8 163  11   3   3   0   3]\n",
      " [  2   1   3   7   1 269   1   0   2   2]\n",
      " [  0   2   0   4   1   3 105   5   4   0]\n",
      " [  3   1   0   2   1   5   0 295   6   6]\n",
      " [  0   0   0   4   2   7   0   8 329   3]\n",
      " [  0   0   0  10   2   3   2   5   3 193]]\n",
      "Model saved as hybrid_rf_model.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 150 out of 150 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 2. Import Libraries\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Feature Extraction Functions\n",
    "\n",
    "# %%\n",
    "def extract_features(img):\n",
    "    \"\"\"\n",
    "    Extract hybrid features: color histogram (HSV), texture (LBP), and shape (contour area).\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    # Color: HSV histogram\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hist_h = cv2.calcHist([hsv], [0], None, [8], [0, 180]).flatten()\n",
    "    hist_s = cv2.calcHist([hsv], [1], None, [8], [0, 256]).flatten()\n",
    "    hist_v = cv2.calcHist([hsv], [2], None, [8], [0, 256]).flatten()\n",
    "    features.extend(hist_h)\n",
    "    features.extend(hist_s)\n",
    "    features.extend(hist_v)\n",
    "    # Texture: Local Binary Pattern (LBP)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    lbp = local_binary_pattern(gray, P=8, R=1, method='uniform')\n",
    "    (hist_lbp, _) = np.histogram(lbp.ravel(), bins=np.arange(0, 11), range=(0, 10))\n",
    "    features.extend(hist_lbp)\n",
    "    # Shape: Largest contour area\n",
    "    contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    largest_area = max([cv2.contourArea(cnt) for cnt in contours], default=0)\n",
    "    features.append(largest_area)\n",
    "    return np.array(features, dtype=np.float32)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Data Preparation\n",
    "\n",
    "# %%\n",
    "# Load cleaned metadata (after EDA cleaning)\n",
    "meta = pd.read_csv(\"Dataset/meta_train.csv\")\n",
    "# If you have already removed duplicates/unreliable images as in your EDA, use the cleaned DataFrame\n",
    "\n",
    "# Map labels to integer indices for classification\n",
    "label2idx = {label: idx for idx, label in enumerate(sorted(meta['label'].unique()))}\n",
    "idx2label = {v: k for k, v in label2idx.items()}\n",
    "meta['label_idx'] = meta['label'].map(label2idx)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Extract Features from Images\n",
    "\n",
    "# %%\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for i, row in tqdm(meta.iterrows(), total=len(meta)):\n",
    "    img_path = f\"Dataset/train_images/{row['label']}/{row['image_id']}\"\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        continue  # Skip missing/corrupted images\n",
    "    img = cv2.resize(img, IMAGE_SIZE)\n",
    "    # Green channel emphasis (from EDA)\n",
    "    img[:, :, 1] = img[:, :, 1] * 0.6\n",
    "    feats = extract_features(img)\n",
    "    features.append(feats)\n",
    "    labels.append(row['label_idx'])\n",
    "\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Feature shape:\", features.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Train/Test Split\n",
    "\n",
    "# %%\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. Handle Class Imbalance (Optional)\n",
    "\n",
    "# %%\n",
    "# Compute class weights from label distribution (from EDA)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
    "print(\"Class weights:\", class_weight_dict)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8. Train Random Forest Classifier\n",
    "\n",
    "# %%\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=150,\n",
    "    class_weight=class_weight_dict,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9. Evaluate Model\n",
    "\n",
    "# %%\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=[idx2label[i] for i in sorted(idx2label)]))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10. Save Model for Later Use\n",
    "\n",
    "# %%\n",
    "joblib.dump(rf, \"hybrid_rf_model_training3.pkl\")\n",
    "print(\"Model saved as hybrid_rf_model_training3.pkl\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 11. How to Use the Model for Inference\n",
    "\n",
    "# %%\n",
    "# Example: Predict on a new image\n",
    "def predict_image(img_path, model, label_map):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, IMAGE_SIZE)\n",
    "    img[:, :, 1] = img[:, :, 1] * 0.6  # Green emphasis\n",
    "    feats = extract_features(img).reshape(1, -1)\n",
    "    pred_idx = model.predict(feats)[0]\n",
    "    return label_map[pred_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8710b3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (10407, 35)\n",
      "Labels shape: (10407,)\n",
      "\n",
      "First 5 rows of features:\n",
      "[[3.0589e+04 1.7571e+04 7.3000e+01 5.0000e+00 1.0000e+01 3.3000e+01\n",
      "  2.7400e+02 1.6210e+03 7.0000e+00 5.4000e+01 1.6460e+03 5.3340e+03\n",
      "  4.2170e+03 5.0670e+03 7.3900e+03 2.6461e+04 2.5380e+03 5.0950e+03\n",
      "  7.1710e+03 9.1970e+03 1.1037e+04 8.7970e+03 4.8910e+03 1.4500e+03\n",
      "  3.6510e+03 4.3790e+03 2.4470e+03 4.6160e+03 1.0375e+04 5.5260e+03\n",
      "  3.4930e+03 4.3890e+03 4.2380e+03 7.0620e+03 4.9729e+04]\n",
      " [3.3928e+04 1.3710e+04 2.8000e+01 4.0000e+00 1.0000e+00 7.0000e+00\n",
      "  4.9100e+02 2.0070e+03 2.0000e+00 2.6000e+01 1.6450e+03 4.6410e+03\n",
      "  5.0870e+03 6.2760e+03 8.3540e+03 2.4145e+04 1.1300e+03 4.0070e+03\n",
      "  7.5840e+03 9.3970e+03 9.1380e+03 1.0188e+04 7.0300e+03 1.7020e+03\n",
      "  4.0160e+03 4.6810e+03 2.2330e+03 4.4610e+03 9.5200e+03 5.2280e+03\n",
      "  3.0360e+03 4.7200e+03 4.5350e+03 7.7460e+03 4.9729e+04]\n",
      " [2.5955e+04 2.1236e+04 2.2200e+02 1.1000e+01 2.1000e+01 5.6000e+01\n",
      "  3.8300e+02 2.2920e+03 2.0000e+01 1.7500e+02 2.8980e+03 5.4820e+03\n",
      "  4.3210e+03 4.9460e+03 8.1160e+03 2.4218e+04 2.7710e+03 5.9670e+03\n",
      "  7.2000e+03 9.1190e+03 9.6360e+03 9.8050e+03 4.1700e+03 1.5080e+03\n",
      "  4.2550e+03 4.7940e+03 2.3570e+03 4.1360e+03 8.5730e+03 5.1970e+03\n",
      "  3.1890e+03 4.9020e+03 4.7800e+03 7.9930e+03 4.9729e+04]\n",
      " [3.2452e+04 1.5349e+04 1.1100e+02 7.0000e+00 7.0000e+00 2.0000e+01\n",
      "  3.6300e+02 1.8670e+03 5.0000e+00 4.1000e+01 9.9300e+02 3.9440e+03\n",
      "  5.0840e+03 5.5770e+03 8.3310e+03 2.6201e+04 2.3270e+03 5.8240e+03\n",
      "  8.2110e+03 7.6250e+03 7.0610e+03 9.8140e+03 7.0880e+03 2.2260e+03\n",
      "  3.9710e+03 4.3780e+03 2.2960e+03 4.4470e+03 9.3340e+03 5.6110e+03\n",
      "  3.2190e+03 4.4900e+03 4.8940e+03 7.5360e+03 4.9729e+04]\n",
      " [3.6239e+04 1.0600e+04 1.8000e+01 3.0000e+00 2.0000e+00 9.0000e+00\n",
      "  6.4500e+02 2.6600e+03 7.0000e+00 3.4000e+01 2.1100e+03 5.4170e+03\n",
      "  5.3620e+03 5.7600e+03 7.4750e+03 2.4011e+04 1.3460e+03 3.8020e+03\n",
      "  6.4410e+03 8.1500e+03 9.2460e+03 1.0701e+04 8.3050e+03 2.1850e+03\n",
      "  3.7820e+03 4.5860e+03 2.0830e+03 4.4740e+03 1.0418e+04 5.6640e+03\n",
      "  3.0770e+03 4.4350e+03 4.3740e+03 7.2830e+03 4.9729e+04]]\n",
      "\n",
      "First 5 labels:\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature shape:\", features.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "\n",
    "# Print the first 5 rows of features\n",
    "print(\"\\nFirst 5 rows of features:\")\n",
    "print(features[:5])\n",
    "\n",
    "# Print the first 5 labels\n",
    "print(\"\\nFirst 5 labels:\")\n",
    "print(labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09ded8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: tungro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 150 out of 150 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Usage:\n",
    "loaded_model = joblib.load(\"hybrid_rf_model_training3.pkl\")\n",
    "result = predict_image(\"Dataset/train_images/tungro/100011.jpg\", loaded_model, idx2label)\n",
    "print(\"Predicted label:\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
